{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3217a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20aef7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from  langserve import add_routes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c721282",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "qroq_apikey = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\", groq_api_key=qroq_apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9bad8411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Chief AI Engineer Albin. It's great to have you here. What brings you to our platform today? Are you working on a new AI project, looking for advice on a specific challenge, or just exploring the latest developments in the field?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 49, 'total_tokens': 104, 'completion_time': 0.102587957, 'prompt_time': 0.002433342, 'queue_time': 0.087961423, 'total_time': 0.105021299}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--e29789e0-30dc-417b-aacc-d827840a9f89-0', usage_metadata={'input_tokens': 49, 'output_tokens': 55, 'total_tokens': 104})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "from langchain_core.messages import HumanMessage\n",
    "human_mesge = [HumanMessage(content=\"Hi, my name is albin and i am cheif ai engineer\")]\n",
    "model.invoke(human_mesge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8ea29a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Albin, and you are a Chief AI Engineer.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 150, 'total_tokens': 165, 'completion_time': 0.022666744, 'prompt_time': 0.008299758, 'queue_time': 0.089754065, 'total_time': 0.030966502}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--4e459b85-703c-4c7c-bba6-56c43fb6052c-0', usage_metadata={'input_tokens': 150, 'output_tokens': 15, 'total_tokens': 165})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "ai_msge = [HumanMessage(content=\"Hi, my name is albin and i am cheif ai engineer\"),\n",
    "           AIMessage(content=\"Nice to meet you, Albin. As a Chief Operations and Maintenance (O&M) Engineer, you play a crucial role in ensuring the smooth operation and reliability of facilities, equipment, and processes. Your expertise is essential in maintaining the efficiency and productivity of the organization.\\n\\nWhat specific challenges or projects are you currently working on, or would you like to discuss about O&M engineering in general? \"),\n",
    "           HumanMessage(content=\"Hey, what is my name ? what i am do ?\"),\n",
    "           ]\n",
    "\n",
    "\n",
    "model.invoke(ai_msge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04c2ed",
   "metadata": {},
   "source": [
    "# Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8cf1ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c95ae9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if multoplie pepole chat with the model => how to hnadle it ==> session\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory() # craete new one if not found if\n",
    "    return store[session_id] #retrun chat associated with that session id\n",
    "        \n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ffe067ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {\"configurable\" : {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9650d3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Albin, I'm happy to meet you and help you on your journey to learning GenAI (Generative Artificial Intelligence). What specific aspects of GenAI would you like to explore or learn about? Would you like to start with the basics, or dive into something more advanced like transformer architectures, generative adversarial networks (GANs), or language models?\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My name is albin, and i am learning GenAI\")],\n",
    "    config=config1\n",
    "    )\n",
    "\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ce8d172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have any information about your name. I'm a large language model, I don't have the ability to retain any personal information about individual users. Each time you interact with me, it's a new conversation and I don't have any prior knowledge about you. If you'd like to share your name with me, I'd be happy to chat with you!\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change > sessionid\n",
    "\n",
    "config1 = {\"configurable\" : {\"session_id\": \"chat2\"}}\n",
    "responce = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],\n",
    "    config=config1\n",
    "    )\n",
    "\n",
    "responce.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0713d130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Albin.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the chat message histroy => sessionid\n",
    "\n",
    "config1 = {\"configurable\" : {\"session_id\": \"chat1\"}}\n",
    "responce = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],\n",
    "    config=config1\n",
    "    )\n",
    "\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ba4ae",
   "metadata": {},
   "source": [
    "# prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e827c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c3f54ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Albin. How can I assist you today?'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\" , \"You are powerful ai model, Answer all question at your very best...\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "result = chain.invoke({\"messages\" : [HumanMessage(content=\"My name is Albin\")]})\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a984118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Albin. Is there something I can help you with today?'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat history\n",
    "with_msge_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "\n",
    "config = {\"configurable\" : {\"session_id\" : \"chat3\"}}\n",
    "res  = with_message_history.invoke(\n",
    "        [HumanMessage(content=\"My name is Albin\")],\n",
    "        config=config\n",
    "    )\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "03e7cfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hallo Albin, wie kann ich dir heute helfen?'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add more complexity\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\" , \"You are powerful ai model, Answer all question at your very best in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "result = chain.invoke(\n",
    "    {\n",
    "        \"messages\" : [HumanMessage(content=\"My name is Albin\")], \n",
    "        \"language\" : \"German\"\n",
    "    }\n",
    ")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b47ad8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Albin. Is there something I can help you with or would you like to chat?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat history\n",
    "with_msge_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\",history_messages_key=\"messages\")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat_mueller_1\"}}\n",
    "res2  = with_message_history.invoke(\n",
    "    {\n",
    "        \"input\" : [HumanMessage(content=\"My name is Albin\")], \n",
    "        \"language\" : \"German\"\n",
    "    },\n",
    "        config=config \n",
    "    )\n",
    "res2.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bf5270",
   "metadata": {},
   "source": [
    "# Manage Chat Histroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb65825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "# ' trim_messages' = reduce how many message we are sending to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32dd7ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are the good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi! I am Müller', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hai!!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='i Like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='oh that nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 9+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='that 11 Müller', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thank you', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='NO probelm', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=70,          #should be exact ´same params name\n",
    "    strategy=\"last\",        #should be exact ´same params name\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages1 = [\n",
    "    SystemMessage(content=\"You are the good assistant\"),\n",
    "    HumanMessage(content=\"Hi! I am Müller\"),\n",
    "    AIMessage(content=\"Hai!!\"),\n",
    "    HumanMessage(content=\"i Like vanilla ice cream\"),\n",
    "    AIMessage(content=\"oh that nice\"),\n",
    "    HumanMessage(content=\"what is 9+2\"),\n",
    "    AIMessage(content=\"that 11 Müller\"),\n",
    "    HumanMessage(content=\"thank you\"),\n",
    "    AIMessage(content=\"NO probelm\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "08a9c46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Albin.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to pass trimmer in a chain\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "trimmed = RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "chain = trimmed | prompt | model\n",
    "\n",
    "response  = chain.invoke({\n",
    "    \"messages\" : messages1 + [HumanMessage(content=\"what is 9+2 ? \")],\n",
    "    \"language\" : \"English\"\n",
    "}\n",
    ")\n",
    "\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b86cc11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da1b417f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You didn't ask a math question. This is the start of our conversation. If you have a math question, feel free to ask, and I'll do my best to help you.\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrpa message hiostory\n",
    "# chat history\n",
    "with_msge_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"input\")\n",
    "\n",
    "config = {\"configurable\" : {\"session_id\" : \"chat5\"}}\n",
    "res2  = with_message_history.invoke(\n",
    "    {\n",
    "        \"input\" : [HumanMessage(content=\"what math question i asked\")], \n",
    "        \"language\" : \"englsih\"\n",
    "    },\n",
    "        config=config \n",
    "    )\n",
    "res2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec58d180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10ba4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f2ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6cdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf15af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b572ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3922a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b9b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffedae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c9f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1a2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8600410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdff85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
