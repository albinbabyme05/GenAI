{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3217a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20aef7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from  langserve import add_routes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c721282",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "qroq_apikey = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\", groq_api_key=qroq_apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bad8411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Albin. As the Chief AI Engineer, I'm sure you have a fascinating job. What specific area of AI are you working in? Are you focused on developing new models, improving existing ones, or exploring the applications of AI in various industries?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 49, 'total_tokens': 105, 'completion_time': 0.091822925, 'prompt_time': 0.002876904, 'queue_time': 0.08842265, 'total_time': 0.094699829}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--fc0c43d9-530b-4f39-af08-a536ea7585d2-0', usage_metadata={'input_tokens': 49, 'output_tokens': 56, 'total_tokens': 105})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "from langchain_core.messages import HumanMessage\n",
    "human_mesge = [HumanMessage(content=\"Hi, my name is albin and i am cheif ai engineer\")]\n",
    "model.invoke(human_mesge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8ea29a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Albin, and you are a Chief AI Engineer.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 150, 'total_tokens': 165, 'completion_time': 0.02297152, 'prompt_time': 0.00813878, 'queue_time': 0.08831208, 'total_time': 0.0311103}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e32974efee', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--70768059-3ff5-482c-9bde-5b6da22c0c8f-0', usage_metadata={'input_tokens': 150, 'output_tokens': 15, 'total_tokens': 165})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "ai_msge = [HumanMessage(content=\"Hi, my name is albin and i am cheif ai engineer\"),\n",
    "           AIMessage(content=\"Nice to meet you, Albin. As a Chief Operations and Maintenance (O&M) Engineer, you play a crucial role in ensuring the smooth operation and reliability of facilities, equipment, and processes. Your expertise is essential in maintaining the efficiency and productivity of the organization.\\n\\nWhat specific challenges or projects are you currently working on, or would you like to discuss about O&M engineering in general? \"),\n",
    "           HumanMessage(content=\"Hey, what is my name ? what i am do ?\"),\n",
    "           ]\n",
    "\n",
    "\n",
    "model.invoke(ai_msge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04c2ed",
   "metadata": {},
   "source": [
    "# Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cf1ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c95ae9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if multoplie pepole chat with the model => how to hnadle it ==> session\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory() # craete new one if not found if\n",
    "    return store[session_id] #retrun chat associated with that session id\n",
    "        \n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffe067ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {\"configurable\" : {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9650d3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Albin. I'm happy to help you learn about GenAI (Generative AI). GenAI is a rapidly evolving field that deals with generating new, original content, such as text, images, music, and more. It's an exciting area of research that has the potential to revolutionize various industries and aspects of our lives.\\n\\nTo get started, let's break down the basics of GenAI:\\n\\n1. **Types of GenAI**: There are several types of GenAI models, including:\\n\\t* **Text-to-Text**: These models generate text based on input text, such as language translation, text summarization, and chatbots.\\n\\t* **Image-to-Image**: These models generate images based on input images, such as image synthesis and image editing.\\n\\t* **Audio-to-Audio**: These models generate audio based on input audio, such as music generation and voice synthesis.\\n2. **Key Concepts**: Understanding the following concepts is essential for learning GenAI:\\n\\t* **Neural Networks**: The building blocks of GenAI models, which are inspired by the structure and function of the human brain.\\n\\t* **Deep Learning**: A subset of machine learning that involves training neural networks on large datasets to enable complex pattern recognition and generation.\\n\\t* **Generative Adversarial Networks (GANs)**: A type of neural network that consists of two models: a generator and a discriminator. The generator creates new data samples, while the discriminator evaluates the generated samples and tries to distinguish them from real data.\\n\\t* **Recurrent Neural Networks (RNNs)**: A type of neural network that is designed to handle sequential data, such as text or speech.\\n3. **Applications**: GenAI has numerous applications across various industries, including:\\n\\t* **Content Creation**: Generating high-quality text, images, and audio content for applications such as social media, advertising, and entertainment.\\n\\t* **Data Augmentation**: Generating new data samples to augment existing datasets, which can help improve the performance of machine learning models.\\n\\t* **Art and Design**: Generating new art and design concepts, such as music, paintings, and sculptures.\\n\\t* **Healthcare**: Generating personalized medicine, medical reports, and diagnoses.\\n\\nNow that we've covered the basics, what specific area of GenAI would you like to explore further, Albin?\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My name is albin, and i am learning GenAI\")],\n",
    "    config=config1\n",
    "    )\n",
    "\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8d172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have any information about your name as our conversation has just started. If you'd like to share it with me, I'd be happy to know.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change > sessionid\n",
    "\n",
    "config1 = {\"configurable\" : {\"session_id\": \"chat2\"}}\n",
    "responce = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],\n",
    "    config=config1\n",
    "    )\n",
    "\n",
    "responce.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713d130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Albin.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the chat message histroy => sessionid\n",
    "\n",
    "config1 = {\"configurable\" : {\"session_id\": \"chat1\"}}\n",
    "responce = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],\n",
    "    config=config1\n",
    "    )\n",
    "\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ba4ae",
   "metadata": {},
   "source": [
    "# prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e827c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c3f54ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Albin. I'm glad to be chatting with you. Is there something I can help you with, or would you like to just have a conversation?\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\" , \"You are powerful ai model, Answer all question at your very best...\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "result = chain.invoke({\"messages\" : [HumanMessage(content=\"My name is Albin\")]})\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a984118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Albin. Is there something I can help you with today?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat history\n",
    "with_msge_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "\n",
    "config = {\"configurable\" : {\"session_id\" : \"chat3\"}}\n",
    "res  = with_message_history.invoke(\n",
    "        [HumanMessage(content=\"My name is Albin\")],\n",
    "        config=config\n",
    "    )\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03e7cfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hallo Albin, ich bin froh, dich kennenzulernen! (Hello Albin, I'm happy to meet you!) Wie kann ich dir heute helfen? (How can I help you today?)\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add more complexity\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\" , \"You are powerful ai model, Answer all question at your very best in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "result = chain.invoke(\n",
    "    {\n",
    "        \"messages\" : [HumanMessage(content=\"My name is Albin\")], \n",
    "        \"language\" : \"German\"\n",
    "    }\n",
    ")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b47ad8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you, Albin again. How's your day going so far?\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat history\n",
    "with_msge_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"input\")\n",
    "\n",
    "config = {\"configurable\" : {\"session_id\" : \"chat4\"}}\n",
    "res2  = with_message_history.invoke(\n",
    "    {\n",
    "        \"input\" : [HumanMessage(content=\"My name is Albin\")], \n",
    "        \"language\" : \"German\"\n",
    "    },\n",
    "        config=config \n",
    "    )\n",
    "res2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb65825e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8600410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdff85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
